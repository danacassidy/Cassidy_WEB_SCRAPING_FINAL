{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "99976a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Deathrow Inmates - Florida Department of Corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32745367",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import time\n",
    "import csv\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be3c1281",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_url = 'http://www.dc.state.fl.us/OffenderSearch/deathrowroster.aspx'\n",
    "res = requests.get(my_url)\n",
    "soup= bs4.BeautifulSoup(res.text,\"html.parser\")\n",
    "\n",
    "    # collect every row in our soup\n",
    "inmate_rows = soup.find_all(\"tr\")\n",
    "\n",
    "    # make a blank list that we will append our information to\n",
    "inmate_links = []\n",
    "\n",
    "    # for every row in our list inmate_rows, we are going to take all of the table data we need in a try and except. \n",
    "    #This try and except exists because some rows don't have the proper data we are looking for and will throw errors unless we stop them ahead of time.\n",
    "for row in inmate_rows:\n",
    "\n",
    "    try:\n",
    "               # getting our table data\n",
    "            a_inmate = row.find(\"a\")\n",
    "            href_inmate = a_inmate.get(\"href\")\n",
    "                #let's make a dictionary. We can assign keys and attributes to ensure that we're inputting the right info into our CSV\n",
    "                # we're also going to strip our text because it's really ugly if we don't.\n",
    "            inmate_links.append(href_inmate)\n",
    "    except:\n",
    "            continue\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5badd219",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "203"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'inmateinfo_dana_webscrapingproject_output.csv' \n",
    "\n",
    "column_headings = ['DC Number', 'Name', 'Race', \"Sex\", \"Birth Date\", \"Inititial Receipt Date\", \"Current Facility\",\n",
    "                      \"Current Custody\", \"Current Release Date\", \"Visiting Request Form - Part 1\", \n",
    "                   \"Visiting Request Form - Part 2\", \"How to Apply for Visitation\"]\n",
    "\n",
    "csvfile = open(filename, 'w', newline='', encoding='utf-8')\n",
    "\n",
    "c = csv.writer(csvfile)\n",
    "c.writerow(column_headings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a20fbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_info(my_url):\n",
    "    inmate = []\n",
    "    combo_url = (\"http://www.dc.state.fl.us/\" + str(my_url))\n",
    "    page =requests.get(combo_url)\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    table = soup.find(\"table\", class_=\"offenderDetails\")\n",
    "    data = table.find_all(\"td\")\n",
    "    \n",
    "    for row in data:\n",
    "        cleaned_inmate = row.get_text().strip()\n",
    "        inmate.append(cleaned_inmate)\n",
    "    \n",
    "    c.writerow(inmate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b533cd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "for link in inmate_links:\n",
    "    scrape_info(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f8905f",
   "metadata": {},
   "outputs": [],
   "source": [
    "offense_column_headings = [\"Offense Date\", \"Offense\", \"Sentence Date\", \"County\",\n",
    "                      \"Case No.\", \"Prison Sentence Length\"]\n",
    "\n",
    "\n",
    "filename = 'offenseinfo_dana_webscrapingproject_output.csv' \n",
    "\n",
    "offense_column_headings = [\"DCNum, Offense Date\", \"Offense\", \"Sentence Date\", \"County\",\n",
    "                      \"Case No.\", \"Prison Sentence Length\"]\n",
    "\n",
    "csvfile = open(filename, 'w', newline='', encoding='utf-8')\n",
    "\n",
    "c = csv.writer(csvfile)\n",
    "c.writerow(offense_column_headings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21523dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def offense_scrape(my_url):\n",
    "    combo_url = (\"http://www.dc.state.fl.us/\" + str(my_url))\n",
    "    page =requests.get(combo_url)\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    big_table = soup.find(\"table\", class_ = \"dcCSStableAlias\")\n",
    "    table = big_table.find_all(\"tr\")\n",
    "\n",
    "    for row in table:\n",
    "        DC_number= soup.find(\"td\")\n",
    "        offense_row.append(DC_number.text)\n",
    "        offense_row = []\n",
    "        data = row.find_all(\"td\")\n",
    "        for d in data:\n",
    "            cleaned_offense_row = d.get_text().strip()\n",
    "            offense_row.append(cleaned_offense_row)\n",
    "            \n",
    "          \n",
    "        c.writerow(offense_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e571f81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for link in inmate_links:\n",
    "    offense_scrape(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e690a095",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
